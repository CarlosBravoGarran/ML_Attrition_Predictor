{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. __Cargar librerías y datos__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Warnings configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el conjunto de datos desde el archivo CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/attrition_availabledata_03.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. __Exploración inicial__\n",
    "\n",
    "En esta sección revisamos la estructura general del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shape = df.shape\n",
    "print(f\"El dataset contiene {dataset_shape[0]} filas y {dataset_shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Attrition']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema de __clasificación__, ya que la variable objetivo (Attrition) es binaria (Yes / No). Esto significa que el modelo debe predecir si un empleado abandonará o no la empresa, en lugar de predecir un valor numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. __Identificamos las variables categóricas y numéricas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "print(\"Variables categóricas:\", categorical_columns)\n",
    "print(\"Variables numéricas:\", numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reclasificamos las variables añadiendo ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "ordinal_columns = [\"Education\", \"JobLevel\", \"EnvironmentSatisfaction\", \"JobSatisfaction\", \"WorkLifeBalance\", \"PerformanceRating\", \"StockOptionLevel\"]\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Eliminamos de numéricas las que hemos clasificado como ordinales\n",
    "numerical_columns = [col for col in numerical_columns if col not in ordinal_columns]\n",
    "\n",
    "print(\"Variables categóricas:\", categorical_columns)\n",
    "print(\"Variables ordinales:\", ordinal_columns)\n",
    "print(\"Variables numéricas:\", numerical_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detección de Variables Categóricas con Alta Cardinalidad\n",
    "\n",
    " Identificamos variables categóricas que pueden generar demasiadas columnas al codificarlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cardinality = df[categorical_columns].nunique().sort_values(ascending=False)\n",
    "display(categorical_cardinality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No consideramos que existan variables categóricas de alta cardinalidad, por lo tanto no necesitaremos realizar ninguna agrupación adicional o una diferente codificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. __Análisis de la variable objetivo__\n",
    "\n",
    "Revisamos la distribución de la variable objetivo para identificar desbalance de clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Attrition\" in df.columns:\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.countplot(x=df[\"Attrition\"], palette=\"viridis\")\n",
    "    plt.title(\"Distribución de la variable objetivo (Attrition)\\n\")\n",
    "    plt.show()\n",
    "    \n",
    "    attrition_counts = df[\"Attrition\"].value_counts(normalize=True)\n",
    "    display(pd.DataFrame(attrition_counts).rename(columns={\"Attrition\": \"Proportion\"}).reset_index(drop=True)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Attrition.value_counts().sort_index().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " El dataset está desbalanceado, con 2466 empleados que no abandonan la empresa (NO) y 474 que sí lo hacen (SI). \n",
    " \n",
    " Esto significa que la mayoría de los empleados no abandonan la empresa, lo que podría causar que un modelo mal entrenado siempre prediga \"No\", logrando una precisión aparente alta, pero sin realmente capturar los casos de abandono.\n",
    "\n",
    "Por lo tanto la solución sería aplicar técnicas como:\n",
    "\n",
    "- Oversampling (SMOTE): Aumentar el número de ejemplos de la clase minoritaria (Yes).\n",
    "- Undersampling: Reducir los casos de la clase mayoritaria (No).\n",
    "- Pesos en los modelos: Ajustar la importancia de la clase minoritaria. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. __Identificar valores nulos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0].to_frame().reset_index()\n",
    "missing_values.columns = [\"Column Name\", \"Missing Values\"]\n",
    "\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que los valores faltantes son muy pocos en comparación con el número de datos totales vamos a tomar las siguientes medidas:\n",
    "- Imputamos valores faltantes en las variables numéricas con la mediana\n",
    "- Imputamos valores faltantes en las variables categóricas con la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=['number']).columns:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "print(\"Valores nulos imputados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. __Identificar variables constantes e identidicativas__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comprobamos si existen columnas con valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df.nunique()\n",
    "\n",
    "constant_columns = df.nunique()[df.nunique() == 1].to_frame().reset_index()\n",
    "constant_columns.columns = [\"Column Name\", \"Unique Value Count\"]\n",
    "constant_columns[\"Unique Value\"] = constant_columns[\"Column Name\"].apply(lambda col: df[col].unique()[0])\n",
    "constant_columns_list = constant_columns[\"Column Name\"].tolist()\n",
    "\n",
    "display(constant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comprobamos si hay columnas con variables ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número total de filas: {len(df)}\")\n",
    "print(f\"Número de valores únicos en EmployeeID: {df['EmployeeID'].nunique()}\")\n",
    "\n",
    "id_columns = [col for col in df.columns if df[col].nunique() == len(df)]\n",
    "print(\"Columnas identificativas detectadas:\", id_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminar las columnas constantes e identificativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=constant_columns_list + id_columns, errors='ignore')\n",
    "numerical_columns = [col for col in numerical_columns if col not in (constant_columns_list + id_columns)]\n",
    "\n",
    "print('Se han eliminado las columnas:', constant_columns_list + id_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. __Crear matriz de correlación__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos la matriz de correlación para entender relaciones entre las variables numéricas, habiendo eliminado ya las constantes y las identificativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", linewidths=0.5, cmap=\"twilight\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.title(\"Matriz de Correlación\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay correlaciones extremadamente altas, cercanas a 1 o -1, las variables no son redundantes ni son fuertemente dependientes entre sí. Pero sí algunas correlaciones moderadas que podemos considerar.\n",
    "\n",
    "__Relación entre antigüedad y experiencia laboral:__\n",
    "\n",
    "- YearsAtCompany y YearsWithCurrManager (0.76): Los empleados que llevan más tiempo en la empresa, más probabilidad de que hayan estado más tiempo con el mismo gerente.\n",
    "- YearsAtCompany y TotalWorkingYears (0.62): Cuanto más tiempo ha trabajado una persona en general, más tiempo puede haber pasado en la empresa actual.\n",
    "\n",
    "__Relación entre PercentSalaryHike y PerformanceRating (0.78):__ Hay una alta correlación entre el incremento salarial y la calificación de desempeño. Los empleados con mejor rendimiento reciben mayores aumentos salariales.\n",
    "\n",
    "- Podríamos evaluar si PercentSalaryHike es redundante, ya que está fuertemente ligada a PerformanceRating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En cuanto al resto, tienen correlaciones muy bajas con todas las demás, lo que indica que pueden ser independientes o estar influenciadas por otros factores no considerados. Así, podríamos revisar si estas variables tienen algún impacto significativo en la variable objetivo, o si pueden eliminarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. __Identificamos la correlación con la variable objetivo__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Attrition\"] = df[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Asegurar que solo trabajamos con columnas numéricas\n",
    "df_corr = df.select_dtypes(include=['number'])\n",
    "attrition_correlation = df_corr.corr()[\"Attrition\"].sort_values()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(y=attrition_correlation.index, x=attrition_correlation.values, palette=\"coolwarm\")\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for index, value in enumerate(attrition_correlation.values):\n",
    "    ax.text(value, index, f\"{value:.2f}\", ha=\"left\", va=\"center\", fontsize=10, color=\"black\")\n",
    "\n",
    "plt.title(\"Correlación de 'Attrition' con el resto de variables\")\n",
    "plt.xlabel(\"Correlación\")\n",
    "plt.ylabel(\"Variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que no hay una variable con una correlación extremadamente fuerte con Attrition, lo que indica que el abandono es un fenómeno multifactorial, es decir todas las variables afectan en algo a la variable objetivo.\n",
    "\n",
    "Las variables de antigüedad (YearsAtCompany, TotalWorkingYears) son las que más influyen en la retención, podemos evaluar las relaciones con YearsWithCurrManager para comprobar si esta última sería redundante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __9. Visualizamos relaciones entre las variables correlacionadas__\n",
    "Realizamos una exploración visual de las relaciones entre las variables con alta correlación, para ayudarnos a decidir si hay redundancias o si algunas variables debemos transformarlas antes de usarlas en un modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizar relaciones entre variables de antigüedad con pairplot\n",
    "sns.pairplot(df, vars=[\"YearsAtCompany\", \"YearsWithCurrManager\", \"TotalWorkingYears\"], diag_kind=\"kde\")\n",
    "plt.suptitle(\"Relaciones entre Antigüedad y Experiencia Laboral\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Relación entre Antigüedad y Experiencia Laboral__\n",
    "\n",
    "- YearsAtCompany y YearsWithCurrManager (0.76): Relación fuerte, posible redundancia.\n",
    "- YearsAtCompany y TotalWorkingYears (0.62): Relación esperada, pero aporta información diferente.\n",
    "- Conclusión: YearsAtCompany o YearsWithCurrManager podría ser redundante.\n",
    "\n",
    "Se podría evaluar impacto en el modelo y eliminar una si es necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar relación entre incremento salarial y evaluación de desempeño\n",
    "sns.pairplot(df, vars=[\"PercentSalaryHike\", \"PerformanceRating\"], diag_kind=\"kde\")\n",
    "plt.suptitle(\"Relación entre Aumento Salarial y Evaluación de Desempeño\", y=1.02)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Relación entre Aumento Salarial y Evaluación de Desempeño__\n",
    "\n",
    "- PerformanceRating tiene pocos valores (3.0 y 4.0), indicando que es categórica y poco variable.\n",
    "- PercentSalaryHike tiene más variabilidad y está correlacionada con PerformanceRating (0.78).\n",
    "- Conclusión: PerformanceRating aporta poca información adicional y podría eliminarse.\n",
    "\n",
    "Se podría considerar eliminarla o transformarla en variable binaria (alta/baja)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
