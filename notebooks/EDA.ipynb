{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. __Cargar librerías y datos__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing and model selection\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "# Matplotlib configuration\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Warnings configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el conjunto de datos desde el archivo CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/attrition_availabledata_03.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. __Exploración inicial__\n",
    "\n",
    "En esta sección revisamos la estructura general del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shape = df.shape\n",
    "print(f\"El dataset contiene {dataset_shape[0]} filas y {dataset_shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Attrition']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema de __clasificación__, ya que la variable objetivo (Attrition) es binaria (Yes / No). Esto significa que el modelo debe predecir si un empleado abandonará o no la empresa, en lugar de predecir un valor numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. __Identificamos las variables categóricas y numéricas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar variables categóricas y numéricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "print(\"Variables categóricas:\", categorical_columns)\n",
    "print(\"Variables numéricas:\", numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reclasificamos las variables añadiendo ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "ordinal_columns = [\"Education\", \"JobLevel\", \"EnvironmentSatisfaction\", \"JobSatisfaction\", \"WorkLifeBalance\", \"PerformanceRating\", \"StockOptionLevel\"]\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Eliminamos de numéricas las que hemos clasificado como ordinales\n",
    "numerical_columns = [col for col in numerical_columns if col not in ordinal_columns]\n",
    "\n",
    "print(\"Variables categóricas:\", categorical_columns)\n",
    "print(\"Variables ordinales:\", ordinal_columns)\n",
    "print(\"Variables numéricas:\", numerical_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detección de Variables Categóricas con Alta Cardinalidad\n",
    "\n",
    " Identificamos variables categóricas que pueden generar demasiadas columnas al codificarlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cardinality = df[categorical_columns].nunique().sort_values(ascending=False)\n",
    "display(categorical_cardinality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No consideramos que existan variables categóricas de alta cardinalidad, por lo tanto no necesitaremos realizar ninguna agrupación adicional o una diferente codificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. __Análisis de la variable objetivo__\n",
    "\n",
    "Revisamos la distribución de la variable objetivo para identificar desbalance de clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance de la variable objetivo \"Attrition\"\n",
    "if \"Attrition\" in df.columns:\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.countplot(x=df[\"Attrition\"], palette=\"viridis\")\n",
    "    plt.title(\"Distribución de la variable objetivo (Attrition)\\n\")\n",
    "    plt.show()\n",
    "    \n",
    "    attrition_counts = df[\"Attrition\"].value_counts(normalize=True)\n",
    "    display(pd.DataFrame(attrition_counts).rename(columns={\"Attrition\": \"Proportion\"}).reset_index(drop=True)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Attrition.value_counts().sort_index().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " El dataset está desbalanceado, con 2466 empleados que no abandonan la empresa (NO) y 474 que sí lo hacen (SI). \n",
    " \n",
    " Esto significa que la mayoría de los empleados no abandonan la empresa, lo que podría causar que un modelo mal entrenado siempre prediga \"No\", logrando una precisión aparente alta, pero sin realmente capturar los casos de abandono.\n",
    "\n",
    "Por lo tanto la solución sería aplicar técnicas como:\n",
    "\n",
    "- Oversampling (SMOTE): Aumentar el número de ejemplos de la clase minoritaria (Yes).\n",
    "- Undersampling: Reducir los casos de la clase mayoritaria (No).\n",
    "- Pesos en los modelos: Ajustar la importancia de la clase minoritaria. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. __Identificar valores nulos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0].to_frame().reset_index()\n",
    "missing_values.columns = [\"Column Name\", \"Missing Values\"]\n",
    "\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que los valores faltantes son muy pocos en comparaciñon con el número de datos totales vamos a tomar las siguientes medidas:\n",
    "- Imputamos valores faltantes en las variables numéricas con la mediana\n",
    "- Imputamos valores faltantes en las variables categóricas con la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=['number']).columns:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "print(\"Valores nulos imputados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. __Identificar variables constantes e identidicativas__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comprobamos si existen columnas con valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df.nunique()\n",
    "\n",
    "constant_columns = df.nunique()[df.nunique() == 1].to_frame().reset_index()\n",
    "constant_columns.columns = [\"Column Name\", \"Unique Value Count\"]\n",
    "constant_columns[\"Unique Value\"] = constant_columns[\"Column Name\"].apply(lambda col: df[col].unique()[0])\n",
    "constant_columns_list = constant_columns[\"Column Name\"].tolist()\n",
    "\n",
    "display(constant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comprobamos si hay columnas con variables ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número total de filas: {len(df)}\")\n",
    "print(f\"Número de valores únicos en EmployeeID: {df['EmployeeID'].nunique()}\")\n",
    "\n",
    "id_columns = [col for col in df.columns if df[col].nunique() == len(df)]\n",
    "print(\"Columnas identificativas detectadas:\", id_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminar las columnas constantes e identificativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=constant_columns_list + id_columns, errors='ignore')\n",
    "numerical_columns = [col for col in numerical_columns if col not in (constant_columns_list + id_columns)]\n",
    "\n",
    "print('Se han eliminado las columnas:', constant_columns_list + id_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. __Crear matriz de correlación__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos la matriz de correlación para entender relaciones entre las variables numéricas, habiendo eliminado ya las constantes y las identificativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", linewidths=0.5, cmap=\"twilight\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.title(\"Matriz de Correlación\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay correlaciones extremadamente altas. No hay correlaciones cercanas a 1 o -1, las variables no son redundantes ni son fuertemente dependientes entre sí. Pero sí algunas correlaciones moderadas que podemos considerar.\n",
    "\n",
    "__Relación entre antigüedad y experiencia laboral (0.76):__ YearsAtCompany y YearsWithCurrManager: Los empleados que llevan más tiempo en la empresa también han estado más tiempo con el mismo gerente.\n",
    "\n",
    "__Relación entre PercentSalaryHike y PerformanceRating (0.78):__ Hay una alta correlación entre el incremento salarial y la calificación de desempeño. Los empleados con mejor rendimiento reciben mayores aumentos salariales.\n",
    "\n",
    "Podríamos evaluar si PercentSalaryHike es redundante, ya que está fuertemente ligada a PerformanceRating.\n",
    "\n",
    "En cuanto al resto, tienen correlaciones muy bajas con todas las demás, lo que indica que pueden ser independientes o estar influenciadas por otros factores no considerados. Así, podríamos revisar si estas variables tienen algún impacto significativo en la variable objetivo, o si pueden eliminarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. __Identificamos la correlación con la variable objetivo__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Attrition\"] = df[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Asegurar que solo trabajamos con columnas numéricas\n",
    "df_corr = df.select_dtypes(include=['number'])\n",
    "attrition_correlation = df_corr.corr()[\"Attrition\"].sort_values(ascending=False)\n",
    "\n",
    "# Mostramos la correlación de 'Attrition' con otras variables\n",
    "print(\"\\nCorrelación de 'Attrition' con otras variables:\")\n",
    "display(attrition_correlation.to_frame().rename(columns={\"Attrition\": \"Correlation\"}))\n",
    "\n",
    "# Visualización de correlaciones con Attrition\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y=attrition_correlation.index, x=attrition_correlation.values, palette=\"coolwarm\")\n",
    "plt.title(\"Correlación de 'Attrition' con Otras Variables\")\n",
    "plt.xlabel(\"Correlación\")\n",
    "plt.ylabel(\"Variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que no hay una variable con una correlación extremadamente fuerte con Attrition, lo que indica que el abandono es un fenómeno multifactorial.\n",
    "\n",
    "Las variables de antigüedad (YearsAtCompany, TotalWorkingYears) son las que más influyen en la retención.\n",
    "\n",
    "El número de empresas previas (NumCompaniesWorked) sugiere que algunos empleados tienen mayor tendencia a la movilidad laboral."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
