{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlos Bravo Garrán - 100474964"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # __Análisis Exploratorio de Datos (EDA)__ \n",
    "\n",
    " En este notebook se realizará un Análisis Exploratorio de Datos (EDA) simplificado del conjunto de datos proporcionado, cuyo objetivo es analizar y comprender los factores que influyen en el abandono laboral (Attrition) en una organización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. __Cargar librerías y datos__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# Warnings configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el conjunto de datos desde el archivo CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/attrition_availabledata_03.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. __Exploración inicial__\n",
    "\n",
    "Revisar la estructura general del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shape = df.shape\n",
    "print(f\"El dataset contiene {dataset_shape[0]} filas y {dataset_shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Attrition']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema de __clasificación__, ya que la variable objetivo (Attrition) es binaria (Yes / No). Esto significa que el modelo debe predecir si un empleado abandonará o no la empresa, en lugar de predecir un valor numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. __Identificamos las variables categóricas y numéricas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "print(\"Variables categóricas:\", categorical_columns)\n",
    "print(\"Variables numéricas:\", numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Reclasificar las variables añadiendo ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "ordinal_columns = [\"Education\", \"JobLevel\", \"EnvironmentSatisfaction\", \"JobSatisfaction\", \"WorkLifeBalance\", \"PerformanceRating\", \"StockOptionLevel\"]\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Eliminamos de numéricas las que hemos clasificado como ordinales\n",
    "numerical_columns = [col for col in numerical_columns if col not in ordinal_columns]\n",
    "\n",
    "print(\"Variables categóricas:\", categorical_columns)\n",
    "print(\"Variables ordinales:\", ordinal_columns)\n",
    "print(\"Variables numéricas:\", numerical_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Detectar variables categóricas con alta cardinalidad\n",
    "\n",
    " Identificar variables categóricas que pueden generar demasiadas columnas al codificarlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cardinality = df[categorical_columns].nunique().sort_values(ascending=False)\n",
    "display(categorical_cardinality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se considera que existan variables categóricas de alta cardinalidad, por lo tanto no se necesitará realizar ninguna agrupación adicional o una diferente codificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. __Análisis de la variable objetivo__\n",
    "\n",
    "Revisar la distribución de la variable objetivo para identificar desbalance de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Attrition\" in df.columns:\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.countplot(x=df[\"Attrition\"], palette=\"viridis\")\n",
    "    plt.title(\"Distribución de la variable objetivo (Attrition)\\n\")\n",
    "    plt.show()\n",
    "    \n",
    "    attrition_counts = df[\"Attrition\"].value_counts(normalize=True)\n",
    "    display(pd.DataFrame(attrition_counts).rename(columns={\"Attrition\": \"Proportion\"}).reset_index(drop=True)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Attrition.value_counts().sort_index().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " El dataset está desbalanceado, con 2466 empleados que no abandonan la empresa (NO) y 474 que sí lo hacen (SI). \n",
    " \n",
    " Esto significa que la mayoría de los empleados no abandonan la empresa, lo que podría causar que un modelo mal entrenado siempre prediga \"No\", logrando una precisión aparente alta, pero sin realmente capturar los casos de abandono.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. __Identificar valores nulos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0].to_frame().reset_index()\n",
    "missing_values.columns = [\"Column Name\", \"Missing Values\"]\n",
    "\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que los valores faltantes son muy pocos en comparación con el número de datos totales vamos a tomar las siguientes medidas:\n",
    "- Imputar valores faltantes en las variables numéricas con la mediana\n",
    "- Imputar valores faltantes en las variables categóricas con la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas diferenciadas por tipo\n",
    "num_cols = [col for col in df.select_dtypes(include=['number']).columns if col not in ordinal_columns]\n",
    "ord_cols = ordinal_columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. __Identificar variables constantes e identidicativas__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Comprobar si existen columnas con valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df.nunique()\n",
    "\n",
    "constant_columns = df.nunique()[df.nunique() == 1].to_frame().reset_index()\n",
    "constant_columns.columns = [\"Column Name\", \"Unique Value Count\"]\n",
    "constant_columns[\"Unique Value\"] = constant_columns[\"Column Name\"].apply(lambda col: df[col].unique()[0])\n",
    "constant_columns_list = constant_columns[\"Column Name\"].tolist()\n",
    "\n",
    "display(constant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Comprobar si hay columnas con variables ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número total de filas: {len(df)}\")\n",
    "\n",
    "unique_values = df.nunique()\n",
    "print(\"Número de valores únicos por columna:\")\n",
    "print(unique_values, \"\\n\")\n",
    "\n",
    "id_columns = [col for col in df.columns if df[col].nunique() == len(df)]\n",
    "print(\"Columnas identificativas detectadas:\", id_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como su nombre indica, _EmployeeID_ es una variable identificativa, por lo que es redundante para el estudio. \n",
    "\n",
    "Por otro lado, la columna _hours_ tiene 2939 valores, 1 menos que el total de filas. Se podría pensar que es identificativa, pero comprobando los valores vemos que simplemente son valores decimales unos distintos de otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Eliminar las columnas constantes e identificativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=constant_columns_list + id_columns, errors='ignore')\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "\n",
    "print('Se han eliminado las columnas:', constant_columns_list + id_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. __Crear matriz de correlación__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar la matriz de correlación para entender relaciones entre las variables numéricas, habiendo eliminado ya las constantes y las identificativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", linewidths=0.5, cmap=\"coolwarm\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.title(\"Matriz de Correlación\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay correlaciones extremadamente altas, cercanas a 1 o -1, las variables no son redundantes ni son fuertemente dependientes entre sí. Pero sí algunas correlaciones moderadas que podemos considerar.\n",
    "\n",
    "__Relación entre antigüedad y experiencia laboral:__\n",
    "\n",
    "- _YearsAtCompany_ y _YearsWithCurrManager_ (0.76): Los empleados que llevan más tiempo en la empresa, más probabilidad de que hayan estado más tiempo con el mismo gerente.\n",
    "- _YearsAtCompany_ y _TotalWorkingYears_ (0.62): Cuanto más tiempo ha trabajado una persona en general, más tiempo puede haber pasado en la empresa actual.\n",
    "\n",
    "__Relación entre _PercentSalaryHike_ y _PerformanceRating_ (0.78):__ Hay una alta correlación entre el incremento salarial y la calificación de desempeño. Los empleados con mejor rendimiento reciben mayores aumentos salariales.\n",
    "\n",
    "- Se podría evaluar si _PercentSalaryHike_ es redundante, ya que está fuertemente ligada a _PerformanceRating_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En cuanto al resto, tienen correlaciones muy bajas con todas las demás, lo que indica que pueden ser independientes o estar influenciadas por otros factores no considerados. Así, se podría revisar si estas variables tienen algún impacto significativo en la variable objetivo, o si pueden eliminarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. __Identificar la correlación con la variable objetivo__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la variable objetivo a numérica\n",
    "df_aux = df.copy()\n",
    "df_aux[\"Attrition\"] = df_aux[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Asegurar que solo trabajamos con columnas numéricas\n",
    "df_corr = df_aux.select_dtypes(include=['number'])\n",
    "attrition_correlation = df_corr.corr()[\"Attrition\"].sort_values()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(y=attrition_correlation.index, x=attrition_correlation.values, palette=\"coolwarm\")\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for index, value in enumerate(attrition_correlation.values):\n",
    "    ax.text(value, index, f\"{value:.2f}\", ha=\"left\", va=\"center\", fontsize=10, color=\"black\")\n",
    "\n",
    "plt.title(\"Correlación de 'Attrition' con el resto de variables\")\n",
    "plt.xlabel(\"Correlación\")\n",
    "plt.ylabel(\"Variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede comprobar que no hay una variable con una correlación extremadamente fuerte con Attrition, pero sí que muchas de ellas tienen una relación muy baja, por ello cabría la posibilidad de considerar su elimiación con el fin de simplificar el modelo.\n",
    "\n",
    "Junto con las horas trabajadas, las variables de antigüedad (_YearsAtCompany_, _TotalWorkingYears_) son las que más influyen en la retención, se pueden evaluar las relaciones con _YearsWithCurrManager_ para comprobar si esta última sería redundante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se podrían eliminar las variables que tienen muy baja correlación con la objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar variables con correlación menor a 0.05 en valor absoluto\n",
    "low_corr_columns = attrition_correlation[abs(attrition_correlation) < 0.05].index.tolist()\n",
    "\n",
    "# Eliminar estas columnas del dataset\n",
    "df_filtered = df.drop(columns=low_corr_columns, errors='ignore')\n",
    "\n",
    "print(f\"Se han eliminado en un dataframe de prueba las siguientes columnas por baja correlación: {low_corr_columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __9. Visualizar relaciones entre las variables correlacionadas__\n",
    "Realizar una exploración visual de las relaciones entre las variables con alta correlación, para ayudar a decidir si hay redundancias o si algunas variables se deben transformar antes de usarlas en un modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizar relaciones entre variables de antigüedad con pairplot\n",
    "sns.pairplot(df, vars=[\"YearsAtCompany\", \"YearsWithCurrManager\", \"TotalWorkingYears\"], diag_kind=\"kde\")\n",
    "plt.suptitle(\"Relaciones entre Antigüedad y Experiencia Laboral\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Relación entre Antigüedad y Experiencia Laboral__\n",
    "\n",
    "- _YearsAtCompany_ y _YearsWithCurrManager_ (0.76): Relación fuerte, posible redundancia.\n",
    "- _YearsAtCompany_ y _TotalWorkingYears_ (0.62): Relación esperada, pero aporta información diferente.\n",
    "- Conclusión: _YearsAtCompany_ o _YearsWithCurrManager_ podría ser redundante.\n",
    "\n",
    "Se podría evaluar impacto en el modelo y eliminar una si es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo identificado y evaluado las variables, comprobando valores nulos, valores constantes e identificativos y las correlaciones entre ellas, se puede pasar a la evaluación de los posibles modelos de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Evaluación de Modelos de Clasificación con Preprocesamiento Avanzado__\n",
    "En esta parte se implementa un pipeline de preprocesamiento y modelado para predecir la variable Attrition en un dataset de empleados. Se va a utilizar validación cruzada para la evaluación interna (inner evaluation) y una evaluación final con un conjunto de prueba independiente (outer evaluation).\n",
    "\n",
    "Los principales pasos seguidos son:\n",
    "\n",
    "1. División de datos en conjuntos de entrenamiento y prueba (2/3 para entrenar el modelo - 1/3 para evaluar el rendimiento final).\n",
    "2. Preprocesamiento de datos, incluyendo imputación, escalado, codificación y reducción de dimensionalidad.\n",
    "3. Evaluación interna (inner evaluation) mediante validación cruzada estratificada.\n",
    "4. Entrenamiento y evaluación final (outer evaluation) con métricas clave como balanced accuracy, accuracy, TPR, TNR y matriz de confusión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1. División de Datos en Train y Test__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se separan las variables predictoras (X) de la variable objetivo (y) y realiza la división de los datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Attrition\"])\n",
    "y = df[\"Attrition\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=1/3, random_state=100474964)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __2. Preprocesamiento de Datos__\n",
    "El preprocesamiento se divide en tres tipos de variables:\n",
    "\n",
    "- Variables numéricas: Se imputan con KNNImputer y se escalan con RobustScaler.\n",
    "- Variables categóricas: Se imputan con la moda (most_frequent) y se codifican con OneHotEncoder, seguido de una reducción de dimensionalidad con PCA(n_components=5).\n",
    "- Variables ordinales: Se imputan con la mediana y se transforman con OrdinalEncoder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Identificación de Tipos de Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = X.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "ordinal_columns = [\"Education\", \"JobLevel\", \"EnvironmentSatisfaction\", \"JobSatisfaction\", \"WorkLifeBalance\", \"PerformanceRating\", \"StockOptionLevel\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Transformaciones por Tipo de Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aplicar Label Encoding a variables ordinales\n",
    "ord_encoder = OrdinalEncoder()\n",
    "df[ordinal_columns] = ord_encoder.fit_transform(df[ordinal_columns])\n",
    "\n",
    "ord_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# Pipeline para datos categóricos\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "    ('pca', PCA(n_components=5))\n",
    "])\n",
    "\n",
    "# Pipeline para datos numéricos\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# ColumnTransformer con todos los preprocesamientos\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, numerical_columns),\n",
    "    ('cat', cat_transformer, categorical_columns),\n",
    "    ('ord', ord_transformer, ordinal_columns)\n",
    "])\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __3. Conversión de Variable Objetivo (Attrition)__\n",
    "Convertimos la variable Attrition a un formato binario (1 para \"Yes\" y 0 para \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"Attrition\" in df.columns:\n",
    "    df[\"Attrition\"] = df[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})\n",
    "else:\n",
    "    raise KeyError(\"La columna 'Attrition' no está en el dataframe. Verifica el dataset cargado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __4. Aplicación del Preprocesador__\n",
    "El preprocesador se ajusta y transforma los datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __5. Evaluación con Modelo Dummy__\n",
    "\n",
    "Se entrena un modelo Dummy para establecer como puntos de referencia:\n",
    "\n",
    "- Balanced Accuracy esperada si el modelo fuera trivial.\n",
    "- Comparación con los modelos entrenados para demostrar su efectividad.\n",
    "\n",
    "Así se podrá verificar si los modelos realmente aprenden patrones o simplemente reflejan la distribución de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Inicializamos el modelo dummy con estrategia \"most_frequent\" (siempre predice la clase mayoritaria)\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_dummy = dummy.predict(X_test_transformed)\n",
    "\n",
    "# Evaluar el rendimiento\n",
    "balanced_acc_dummy = balanced_accuracy_score(y_test, y_pred_dummy)\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm_dummy = confusion_matrix(y_test, y_pred_dummy)\n",
    "\n",
    "# Extraer TP, TN, FP, FN\n",
    "TN, FP, FN, TP = cm_dummy.ravel()\n",
    "\n",
    "# Calcular métricas TPR y TNR\n",
    "TPR_dummy = TP / (TP + FN) if (TP + FN) != 0 else 0  # Sensibilidad\n",
    "TNR_dummy = TN / (TN + FP) if (TN + FP) != 0 else 0  # Especificidad\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Balanced Accuracy Modelo Dummy: {balanced_acc_dummy:.4f}\")\n",
    "print(f\"Accuracy Modelo Dummy: {accuracy_dummy:.4f}\")\n",
    "print(f\"True Positive Rate (TPR) Modelo Dummy: {TPR_dummy:.4f}\")\n",
    "print(f\"True Negative Rate (TNR) Modelo Dummy: {TNR_dummy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __6. Definición de los Modelos con Pipeline__\n",
    "Se construye un pipeline que incluye el preprocesamiento y el modelo de clasificación (Regresión Logística con balanceo de clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', tree.DecisionTreeClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_knn = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "clf_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __7. Evaluación Interna (Inner Evaluation)__\n",
    "Para la evaluación interna, se utiliza validación cruzada estratificada (StratifiedKFold) con 5 divisiones (n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=100474964)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train, cv=skf, scoring='balanced_accuracy')\n",
    "print(f\"Balanced Accuracy (inner evaluation): {np.mean(cross_val_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __8. Entrenamiento del Modelo__\n",
    "El modelo se ajusta con todo el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __9. Evaluación con Test (Outer Evaluation)__\n",
    "Se realiza la predicción sobre el conjunto de prueba y se calculan las métricas principales:\n",
    "\n",
    "- Balanced Accuracy: Promedio de TPR y TNR.\n",
    "- Accuracy: Proporción de predicciones correctas.\n",
    "- TPR (Sensibilidad/Recall): Qué tan bien el modelo detecta los casos positivos.\n",
    "- TNR (Especificidad): Qué tan bien el modelo detecta los casos negativos.\n",
    "- Matriz de Confusión: Visualización detallada de aciertos y errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calcular TPR (True Positive Rate) y TNR (True Negative Rate)\n",
    "TP = conf_matrix[1, 1]  # Verdaderos positivos\n",
    "FN = conf_matrix[1, 0]  # Falsos negativos\n",
    "TN = conf_matrix[0, 0]  # Verdaderos negativos\n",
    "FP = conf_matrix[0, 1]  # Falsos positivos\n",
    "\n",
    "TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensibilidad o Recall\n",
    "TNR = TN / (TN + FP) if (TN + FP) > 0 else 0  # Especificidad\n",
    "classif_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Evaluación final del modelo:\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"TPR (Sensibilidad/Recall): {TPR:.4f}\")\n",
    "print(f\"TNR (Especificidad): {TNR:.4f}\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(classif_report)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
